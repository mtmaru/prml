{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRML 第1章 序論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本章の目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 機械学習に共通する概念を説明する。\n",
    "* 機械学習を理解するうえで必要な3つのツールについての導入を行う。\n",
    "    * 確率論\n",
    "    * 決定理論\n",
    "    * 情報理論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.1 例：多項式曲線フィッティング\n",
    "* 1.2 確率論\n",
    "    * 1.2.1 確率密度\n",
    "    * 1.2.2 期待値と分散\n",
    "    * 1.2.3 ベイズ確率\n",
    "    * 1.2.4 ガウス分布\n",
    "    * 1.2.5 曲線フィッティング再訪\n",
    "    * 1.2.6 ベイズ曲線フィッティング\n",
    "* 1.3 モデル選択\n",
    "* 1.4 次元の呪い\n",
    "* 1.5 決定理論\n",
    "    * 1.5.1 誤識別率の最小化\n",
    "    * 1.5.2 期待損失の最小化\n",
    "    * 1.5.3 棄却オプション\n",
    "    * 1.5.4 推論と決定\n",
    "    * 1.5.5 回帰のための損失関数\n",
    "* 1.6 情報理論\n",
    "    * 1.6.1 相対エントロピーと相互情報量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 詳細"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習の構成要素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例として、手書き数字の認識を考える。\n",
    "\n",
    "$\\textbf{t} = \\textbf{y}(\\textbf{x})$\n",
    "\n",
    "* 入力ベクトル $\\textbf{x}$ : 手書き数字画像\n",
    "* 目標ベクトル (target vector) $\\textbf{t}$ : 手書き数字画像が表している数字\n",
    "* モデル $\\textbf{y}$ : 手書き数字画像 $\\textbf{x}$ を入力すると、その手書き数字画像が表している数字 $\\textbf{t}$ を返す関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習で使うデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 訓練集合 (training set) : モデルのパラメータを調節するために使う事例の集合\n",
    "    * 事例 : 1枚の手書き数字画像と、その手書き数字画像が表している数字\n",
    "        * 入力ベクトル : 手書き数字画像\n",
    "        * 目標ベクトル : 手書き数字画像が表している数字\n",
    "* テスト集合 (test set) : 訓練集合とは別の、新たな事例の集合\n",
    "    * 事例 : 1枚の手書き数字画像\n",
    "        * 入力ベクトル : 手書き数字画像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習の段階"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 前処理 (preprocessing) : もともとの入力変数を、新しい変数に変換すること\n",
    "    * 特徴抽出 (feature extraction) : パターン認識が容易になるような前処理を施すこと\n",
    "* 訓練 (training)、学習 (learning) : 訓練集合に基づいてモデルのパラメータを調節すること\n",
    "\n",
    "この時点では明確に書かれていないが、訓練の定義から以下の3点が読み取れる。\n",
    "\n",
    "* モデルはパラメータを持つ\n",
    "* モデルのパラメータは訓練集合に基づいて調節する必要がある\n",
    "* モデルには、パラメータ調節済みの「学習済みのモデル」と未調節の「未学習のモデル」の2種類が存在する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習の種類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 教師あり学習 (supervised learning) : 訓練集合が入力ベクトルと目標ベクトルで構成されているパターン認識の問題\n",
    "    * クラス分類 (classification) : 入力ベクトルに対する出力がカテゴリである問題\n",
    "    * 回帰 (regression) : 入力ベクトルに対する出力が連続値である問題\n",
    "* 教師なし学習 (unsupervised learning) : 訓練集合が入力ベクトルのみで構成されているパターン認識の問題\n",
    "    * クラスタリング (clustering) : 類似した事例のグループを見つける問題\n",
    "    * 密度推定 (density estimation) : 入力空間におけるデータの分布を求める問題\n",
    "    * 視覚化 (visualization) : データを視覚的に捉えられるようにする問題。高次元データを2～3次元に射影するなど\n",
    "* 強化学習 (reinforcement learning) : ある状況下 (＝入力ベクトル) で報酬を最大化する行動 (目標ベクトル) を、試行錯誤を通じて見つける問題。<br>一般的には、探索と知識利用のトレードオフになる。\n",
    "    * 探索 (exploration) : 新しい行動がどれくらい有効であるか試すこと\n",
    "    * 知識利用 (exploitation) : 高い報酬が得られるとわかっている行動をとること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習の課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 汎化 (generalization) : 訓練に使った事例とは異なる事例を正しく分類する能力。<br>訓練集合は入力されうる事例の一部に過ぎないので、それ以外の事例に対する分類能力は中心的な課題となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疑問点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用語の使い分け"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はっきりと違いを定義していないが、文脈に応じて使い分けている (っぽい) 用語が複数ある。自分の理解は以下の通り。\n",
    "\n",
    "* パターン認識 / 機械学習\n",
    "    * パターン認識 : データに潜むパターンを見つけ出すこと (目的)\n",
    "    * 機械学習 : モデルのパラメータをデータから適応的に調節すること (パターン認識を実現する手段、として使えるもの)\n",
    "* パターン認識アルゴリズム / 学習アルゴリズム\n",
    "    * パターン認識アルゴリズム : 読者の興味が「パターン認識」にある文脈で使う。モデリングの過程を解説しているときなど\n",
    "    * 学習アルゴリズム : 読者の興味が「モデルのパラメータ調節」にある文脈で使う。学習方法を解説しているときなど\n",
    "* パターン / 情報 / データ (DIKWモデルに近い？)\n",
    "    * パターン : 事象の裏に潜む規則性\n",
    "    * 情報 : パターンを見つけ出す役に立つもの\n",
    "    * データ : 情報を数値や記号として表現したもの\n",
    "* 入力ベクトル / 入力変数 / 特徴\n",
    "    * 入力ベクトル : モデルの入力となるデータをベクトル形式で表現したもの\n",
    "    * 入力変数 : モデルの入力となるデータ全般。入力ベクトルの要素を指すかもしれないし、行列などベクトル以外の入力を指すかもしれない\n",
    "    * 特徴 : 入力変数がパターン認識に有用な情報を含んでいることを強調したいときに使う\n",
    "* ○○事例 / ○○集合 / ○○集合のデータ点 / ○○データ\n",
    "    * ○○事例 : 観測された事象\n",
    "    * ○○集合 : 事例を集めたもの。データ点を集めたものを指すこともある\n",
    "    * ○○集合のデータ点 : 観測された事象に対する確率変数の実測値\n",
    "    * ○○データ : データ点でも集合でも構わない文脈で使う\n",
    "* 関数 / モデル\n",
    "    * 関数 : (いわゆる関数)\n",
    "    * モデル : 関数のうち、入力ベクトルを受け取り目標ベクトルを返すもの\n",
    "* 訓練 / 学習\n",
    "    * 訓練 : 主語が人間。人間が機械を訓練する\n",
    "    * 学習 : 主語が機械。機械が学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
